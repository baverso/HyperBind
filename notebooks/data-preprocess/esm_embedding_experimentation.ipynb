{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43788772-9351-4061-b7b2-740b87d024c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26a1d0c-cf01-456a-a79b-822a930e9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"scripts\"))\n",
    "\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.insert(0, scripts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26241f28-ca9d-4ad3-965d-3990442eb871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b28fb31-a852-4ca7-b31e-4d8b01a998ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"/Volumes/LaCie_d2_Professional_Media/absolut_antibody/PerClass/RawBindingsPerClassMurine/extracted/processed/\"\n",
    "df = data_ingestion.load_processed_csvs(dirpath, ['3KR3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17b0bea6-e763-4d4a-91a2-167be6ea5ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(dirpath,'3KR3_D_consolidated.csv')\n",
    "df = pd.read_csv(fpath,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b1298e9-81a6-4e02-a902-4d5a1ca7cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import esm\n",
    "\n",
    "# Load the ESM-2 variant (adjust the variant name if desired)\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()  # set to evaluation mode\n",
    "\n",
    "# Prepare sample sequences as a list of (name, sequence) tuples.\n",
    "data = [\n",
    "    (\"protein1\", \"MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQ\"),\n",
    "    (\"protein2\", \"MGSSHHHHHHSSGLVPRGSHMASMTGGQQMGRDLYDDDDKDP\"),\n",
    "    # Add more sequences as needed\n",
    "]\n",
    "\n",
    "# Convert the data into batch format required by the model.\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")\n",
    "    batch_tokens = batch_tokens.to(\"cuda\")\n",
    "\n",
    "# For ESM-2, use the last layer (model.num_layers) for representations.\n",
    "layer = model.num_layers\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[layer], return_contacts=False)\n",
    "token_representations = results[\"representations\"][layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f7c7d-ed99-4d08-b48b-3bcf94257878",
   "metadata": {},
   "source": [
    "## Assume that the ESM-2 model is already loaded and used to generate token representations.\n",
    "For example:\n",
    "results = model(batch_tokens, repr_layers=[model.num_layers], return_contacts=False)\n",
    "token_representations = results[\"representations\"][model.num_layers]\n",
    "and that \"data\" is a list of (name, sequence) tuples.\n",
    "\n",
    "token_representations is a tensor of shape [batch_size, L, D] where L is the number of tokens\n",
    "(including special tokens) and D is the hidden dimension (assumed to be 1280 here).\n",
    "\n",
    "•\tSimple Average Embedding:\n",
    "We average the token embeddings corresponding to the actual amino acid sequence (excluding the first special token) because the start token might not capture the detailed information in the sequence. We then project this vector from 1280 dimensions to 1024 (if desired) using a linear layer.\n",
    "\t\n",
    " •\tAdvanced Embeddings:\n",
    " \t1.\tCLS Token Only:\n",
    "Use only the model’s [CLS] (or start-of-sequence) token as the sequence representation. This is the standard approach in many transformer models for classification tasks, though it sometimes loses finer-grained information.\n",
    "\n",
    "\t2.\tMean Pooling:\n",
    "Compute the average of all token representations (typically excluding the special tokens). This approach tends to capture the overall content of the sequence and is often more robust than the CLS token alone.\n",
    "\n",
    "\t3.\tCLS, MIN, MAX, MEAN Concatenation:\n",
    "Concatenate the CLS token with statistics computed over the sequence tokens:\n",
    "\t•\tMIN: Elementwise minimum over token embeddings.\n",
    "\t•\tMAX: Elementwise maximum.\n",
    "\t•\tMEAN: Elementwise average.\n",
    "This yields a vector with 4×(hidden dimension) dimensions (e.g., 4×1280 = 5120 dims for an ESM model with 1280 hidden units). This strategy is popular because it provides multiple views of the sequence’s distribution.\n",
    "\n",
    "\t4.\tCLS, MEAN, and Standard Deviation Concatenation:\n",
    "Instead of using min and max, you can compute the elementwise standard deviation of the token embeddings along with the CLS token and the mean. This produces a 3×(hidden dimension) vector (e.g., 3×1280 = 3840 dims) and captures both central tendency and dispersion.\n",
    "\n",
    "\t5.\tLayer-wise Concatenation:\n",
    "Instead of taking only the last layer’s output, you can concatenate representations from multiple layers (e.g., last and penultimate layers) to capture multi-scale information. For example, concatenating two layers would double the embedding size.\n",
    "\n",
    "\t6.\tAttention-based Pooling:\n",
    "Learn attention weights for each token and compute a weighted average of token embeddings. You can combine this with the CLS token or other summary statistics.\n",
    "\n",
    "    We concatenate:\n",
    "\n",
    "    •\tThe CLS token (position 0),\n",
    "\n",
    "    •\tThe elementwise minimum across the sequence tokens,\n",
    "\n",
    "    •\tThe elementwise maximum across the sequence tokens,\n",
    "\n",
    "    •\tThe elementwise mean across the sequence tokens.\n",
    "\n",
    "This yields a vector of size 4 × 1280 = 5120 dimensions. This approach leverages multiple statistical summaries of the token embeddings, potentially capturing richer information about the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "739308c9-f482-4ae5-9d7a-f06cea3e803c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple embedding (projected to 1024 dims) shape: (1024,)\n"
     ]
    }
   ],
   "source": [
    "# --- Option 1: Simple Average Embedding (excluding CLS token) ---\n",
    "simple_embeddings = []\n",
    "for i, (name, seq) in enumerate(data):\n",
    "    # Exclude the first token (CLS or start-of-sequence)\n",
    "    avg_embedding = token_representations[i, 1:len(seq)+1].mean(0)\n",
    "    simple_embeddings.append(avg_embedding)\n",
    "\n",
    "# Optionally project to a fixed dimension (e.g., 1024) if desired.\n",
    "hidden_dim = simple_embeddings[0].shape[0]  # e.g., 1280\n",
    "target_dim = 1024\n",
    "if hidden_dim != target_dim:\n",
    "    projector = nn.Linear(hidden_dim, target_dim)\n",
    "    if torch.cuda.is_available():\n",
    "        projector = projector.to(\"cuda\")\n",
    "    simple_embeddings_1024 = [\n",
    "        projector(e.unsqueeze(0)).squeeze(0).detach().cpu().numpy() for e in simple_embeddings\n",
    "    ]\n",
    "else:\n",
    "    simple_embeddings_1024 = [e.cpu().numpy() for e in simple_embeddings]\n",
    "\n",
    "print(\"Simple embedding (projected to 1024 dims) shape:\", simple_embeddings_1024[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec1c1e6e-fe4d-49ea-88bf-6c1df3d61386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Option 2: Advanced Embedding: CLS, MIN, MAX, MEAN Concatenation ---\n",
    "advanced_embeddings = []\n",
    "for i, (name, seq) in enumerate(data):\n",
    "    # CLS token is at index 0\n",
    "    cls_token = token_representations[i, 0]\n",
    "    # Sequence tokens: indices 1 to len(seq)+1 (excluding special tokens)\n",
    "    seq_tokens = token_representations[i, 1:len(seq)+1]\n",
    "    # Compute elementwise min, max, and mean over the sequence tokens.\n",
    "    min_vec = seq_tokens.min(dim=0)[0]\n",
    "    max_vec = seq_tokens.max(dim=0)[0]\n",
    "    mean_vec = seq_tokens.mean(dim=0)\n",
    "    # Concatenate the CLS token, min, max, and mean vectors.\n",
    "    concat_vec = torch.cat([cls_token, min_vec, max_vec, mean_vec], dim=0)\n",
    "    advanced_embeddings.append(concat_vec.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "874607f9-8b73-4e9d-a45b-c9fd717d77c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5120,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_embeddings[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31d88141-f831-4201-a8be-09088c886cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced (CLS, MIN, MAX, MEAN) embedding shape: (5120,)\n",
      "Advanced (CLS, MEAN, STD) embedding shape: (3840,)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Option 1: CLS, MIN, MAX, MEAN Concatenation (4 x D dimensions)\n",
    "# ---------------------------\n",
    "advanced_embeddings_concat = []\n",
    "for i, (name, seq) in enumerate(data):\n",
    "    cls_token = token_representations[i, 0]  # CLS token at index 0\n",
    "    # Use only the tokens corresponding to the sequence (exclude special tokens)\n",
    "    seq_tokens = token_representations[i, 1:len(seq)+1]\n",
    "    min_vec = seq_tokens.min(dim=0)[0]\n",
    "    max_vec = seq_tokens.max(dim=0)[0]\n",
    "    mean_vec = seq_tokens.mean(dim=0)\n",
    "    concat_vec = torch.cat([cls_token, min_vec, max_vec, mean_vec], dim=0)\n",
    "    advanced_embeddings_concat.append(concat_vec.cpu().numpy())\n",
    "    \n",
    "print(\"Advanced (CLS, MIN, MAX, MEAN) embedding shape:\", advanced_embeddings_concat[0].shape)\n",
    "# Expected shape: 4 * D, e.g., 4 * 1280 = 5120 dims.\n",
    "\n",
    "# ---------------------------\n",
    "# Option 2: CLS, MEAN, STD Concatenation (3 x D dimensions)\n",
    "# ---------------------------\n",
    "advanced_embeddings_std = []\n",
    "for i, (name, seq) in enumerate(data):\n",
    "    cls_token = token_representations[i, 0]  # CLS token at index 0\n",
    "    seq_tokens = token_representations[i, 1:len(seq)+1]\n",
    "    mean_vec = seq_tokens.mean(dim=0)\n",
    "    std_vec = seq_tokens.std(dim=0)\n",
    "    concat_vec = torch.cat([cls_token, mean_vec, std_vec], dim=0)\n",
    "    advanced_embeddings_std.append(concat_vec.cpu().numpy())\n",
    "    \n",
    "print(\"Advanced (CLS, MEAN, STD) embedding shape:\", advanced_embeddings_std[0].shape)\n",
    "# Expected shape: 3 * D, e.g., 3 * 1280 = 3840 dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec51e9ed-d488-46f1-8433-b67c658caee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------\n",
    "# 1. Generate Sequence Embeddings with ESM-2\n",
    "# -----------------------\n",
    "\n",
    "# Load the ESM-2 model (variant esm2_t33_650M_UR50D) and its alphabet.\n",
    "esm2_model, esm2_alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "esm2_batch_converter = esm2_alphabet.get_batch_converter()\n",
    "esm2_model.eval()\n",
    "\n",
    "# Sample protein sequence\n",
    "sequence = \"MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQ\"\n",
    "data = [(\"protein1\", sequence)]\n",
    "\n",
    "# Convert data to batch format.\n",
    "batch_labels, batch_strs, batch_tokens = esm2_batch_converter(data)\n",
    "if torch.cuda.is_available():\n",
    "    esm2_model = esm2_model.to(\"cuda\")\n",
    "    batch_tokens = batch_tokens.to(\"cuda\")\n",
    "\n",
    "# Generate sequence embeddings (using the last layer representation).\n",
    "with torch.no_grad():\n",
    "    esm2_results = esm2_model(batch_tokens, repr_layers=[esm2_model.num_layers], return_contacts=False)\n",
    "# Average token representations (exclude special tokens) to get a single embedding vector.\n",
    "seq_embedding = esm2_results[\"representations\"][esm2_model.num_layers][0, 1:len(sequence)+1].mean(0).cpu().numpy()\n",
    "print(\"ESM-2 sequence embedding shape:\", seq_embedding.shape)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 2. Generate Structure Prediction (and Structural Features) with ESMFold\n",
    "# -----------------------\n",
    "\n",
    "# Load the ESMFold model (ESMFold v1)\n",
    "esmfold_model, esmfold_alphabet = esm.pretrained.esmfold_v1()\n",
    "esmfold_model.eval()\n",
    "\n",
    "# ESMFold takes a raw sequence as input.\n",
    "with torch.no_grad():\n",
    "    # ESMFold returns a dictionary that includes predicted 3D coordinates (under key 'coords')\n",
    "    # and other outputs such as pLDDT confidence scores.\n",
    "    fold_result = esmfold_model(sequence)\n",
    "    \n",
    "# Extract the predicted structure coordinates.\n",
    "coords = fold_result['coords']  # shape typically [L, 3] (for a sequence of length L)\n",
    "print(\"Predicted structure coordinates shape:\", coords.shape)\n",
    "\n",
    "# Optionally, if ESMFold exposes internal representations (e.g., hidden states),\n",
    "# you could extract them and aggregate them as \"structural embeddings\".\n",
    "# For example, if fold_result had a key \"hidden_states\", you might do:\n",
    "# struct_embedding = fold_result[\"hidden_states\"][-1].mean(dim=0).cpu().numpy()\n",
    "# (This depends on the ESMFold API and whether such representations are available.)\n",
    "  \n",
    "# -----------------------\n",
    "# 3. (Optional) Fuse Sequence and Structure Embeddings\n",
    "# -----------------------\n",
    "\n",
    "# One common strategy is to concatenate the sequence embedding and a structural embedding.\n",
    "# For demonstration, assume we only use the sequence embedding and the flattened structure coordinates.\n",
    "# You might also compute summary statistics (e.g., mean, variance) over the coordinates.\n",
    "struct_embedding = coords.mean(axis=0)  # Simple example: mean coordinate per dimension.\n",
    "print(\"Mean structural embedding shape:\", struct_embedding.shape)\n",
    "\n",
    "# Concatenate both embeddings.\n",
    "import numpy as np\n",
    "combined_embedding = np.concatenate([seq_embedding, struct_embedding])\n",
    "print(\"Combined embedding shape:\", combined_embedding.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
